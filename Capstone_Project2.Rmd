---
title: "Intro to DS Capstone Project"
author: "Derek J. Dennis"
date: "May 11, 2018"
output: html_document
---

```{r setup, include=FALSE}

```

## Introduction

The prediction of the outcomes of sports matches garners a lot of interest within the respective leagues.  All the major world sports have opportunities for which one can predict the outcome of the match.  The one major application for this is sports betting.  Globally, $90.9 billion dollars is wagered on all types of sports1.  Even in the United States, where sports wagering is largely illegal, there is a significant amount of wagering on these matches.  With this in mind, if there is any method to help predict the outcome of games, it could result in significant revenue, not only from personal betting, but also from sharing this information with others.  One can only look on the internet to find many outlets that claim great predictive skills.  These outlets charge money for memberships to see these predictions and use them to their advantage.  While there has been proven methods to succeed in predicting sports like basketball and baseball, on would be hard pressed to find consistent success in predicting outcomes in American Football.  The goal of the statistical analysis referenced in this paper is to determine if a proprietary offensive and defensive formula developed by the author can predict the outcomes of college football games at a success rate greater than 52.4%.

## Understanding the Goal of the Exercise

There are many different ways to make a prediction on an American Football game.  The most prevalent of these is to pick a game against the spread.  The spread is a number generated by a bookmaker that gives the more powerful team a handicap so that the wager can be considered even.  For example:  For the 2017 National Championship Game in College Football, the Alabama Crimson Tide played the Georgia Bulldogs.  The oddsmaker listed the game like this, Alabama (-4) over Georgia.  In other words, Alabama was a four-point favorite against Georgia.  This means, in betting parlance, that if one were to pick Alabama to win this bet, Alabama would have to win by more than four points, not just win outright.  The actual result of the game was Alabama 26 – Georgia 23 in overtime.  Therefore, the bettors that chose Alabama actually lost the bet.
While there are some groups that claim to pick winners at a staggering rate, it is very hard to find anyone who can consistently pick winners at a favorable percentage for all games.  This is especially true for straight computer algorithms.  There are too many variables to account for in anyone game to be consistently correct.  Injuries, weather conditions, and home field advantage are hard to calculate.  When using algorithms for past performance, it is also hard to account for a team’s schedule strength.  This means that a team with really good statistics can be favored in a particular calculation only because they played bottom rung talent up until the game in question.  When compared to a team that has lesser statistics but played many of their games against upper echelon talent, it can be hard to discern which team is better, statically speaking.
The goal of this exercise is to see if any analysis can net a winning result in outcomes at least 52.4% of the time.  At this point, there needs to be some explanation since the obvious percentage would be better than 50%.  In the betting industry, there is a term called “juice.”  This is the amount of money that is skimmed off the top of an even bet that goes to the oddsmaker for every win.  Here is an example:  Going back to the National Championship Game, if a bettor wagered $10 dollars on the Alabama Crimson Tide, the bettor would have lost $10.  If the bettor would have wagered that same amount on the Georgia Bulldogs, the bettor would have received $19.10.  That is $10 from the original bet plus an additional $9.10 for the winning wager, not $20 ($10 + $10).  The goal of any bettor who wagers on spread bets needs to be right more than 52.4% of the time to cover this discrepancy.

## Data
A quick look at the starting data can be shown here:
```{r}
print(Capstone_CFA_Scores_and_Lines)
```


The fields included in this data frame are:
1. Year - The year that the game was played
2. Week - The numbered week during the particular year that the game was played
3. Away Team - The team that traveled to the game in question
4. Home Team - The team that away team is playing against
5. Line - As explained earlier, the oddsmaker's handicap to make this an even bet
6. Over/Under - The oddsmaker's guess as to the total number of points that will be scored in the game.  The bettor would then pick over or under that number.
7. ATOR - Proprietary offensive ranking for the away team
8. ATDR - Proprietary defensive ranking for the away team
9. HTOR - Proprietary offensive ranking for the home team
10. HTDR - Proprietary defensive ranking for the home team
11. Score - Final score of the game

This data was obtained from common sports sources:  espn.com, ncaasports.com and cfbstats.com

## Data Wrangling

Fortunately, the data was mostly neat at the time it was transfered to R as a .csv file.  There were a few alterations: The score had to be expanded so that each column had the away team and home team result.  This is so calculations on the total points could be done later.  There would also be some filtering of the neutral column do that calculations can be performed on the success rate of the algorithm at a neutral site.  Finally, the Over/Under column will be filtered so that we can do statistical testing vs that particular number.

## Statistical Analysis

One of the main points of this study is to see if the proprietary ratings would be robust enough to use for all of the calculations.  The best way to do this is to compare the calculations to the points scored for each team and the points allowed for each team over the eight year span.  To do this, a linear regression will be performed.  Two graphs will be plotted to show points scored vs final team rating for offense and defense.  The results are below.

```{r}

```

```{r}

```


It can be shown that there is a very correlations with the ratings and the points per game.  This could be helpful in predicting the outcomes of the games.

## Testing

Using the data from the data sets as well as the regression statistics for the two lines that were plotted, several tests will be run to determine how well the ratings predict future games.  The tests are as follows:

1.  Taking the sum of the differences between the two teams' offensive and defensive rating.  This number will be multiplied by 100 and compared to the line.  If the number is more than the line, the calculation will predict the away team.  If the number is lower, the home team will be predicted.
2.  Using the regression model, the equation will assign a score for offense and a score for defense for each team, We can test the sum of the differences similarly to test 1.
3.  Using the filtered data, compare the results year by year to see if a) there is any consistency to the data and b) if there are any trends.
4.  Filtering the data in different quarters of every year so that it is possible that the results get better as the season progresses and more data for each team is produced.
5.  Assigning a designation to each predictor by the following :Home team favorite, home team underdog, away team favorite, away team underdog, neutral site games.  This will determine if there is any favoritism towards home vs away or underdog vs favorite.
6.  Using the linear regression model to predict the number of points each team will score and thus be able to predict the outcome of an Over/Under bet.

## Results




## Findings

1.  Overall this method cannot accurately predict outcomes of football games at a success rate that is equitible to the baseline of 52.4%
2.  Even though the regression model is highly correlated when comparing the proprietary ratings and the points per game, it does a very poor job of predicting the outcome of Over/Under bets (less than 49% success).
3.  It appears that the prediction that the model will get better at predicting games as the season goes on is valid.  For weeks 10-13 in each year of the model, the success rate was 53.8%.  While the last quarter had poor results, this can be attrributed to the fact that there was a poor showing in weeks 14 and 15 (129 wins - 130 losses).  If this result were subtracted out, the remaining games comprising the bowl season had a favroable result (160 wins - 141 losses).
4.  The data does show evidence that the model does better at picking away teams as winners against the spread versus the home team (53% vs 50%).  This could be attributed to the fact that oddsmakers will add points to the line favoring the home team just because they are playing at home.  Remember that the algorithm does not take this into account.

## What's Next

1.  There needs to be an understanding as to why the regression model did not accurately predict spread and Over/Under wagers.  One would think that there would be more success since there was high correlation between points and the ratings, the results didn't pan out.  It is understood that inuries, schedule strength and weather could play roles in a particular game's out come.  It is surprising to think that the results were so poor.
2.  The ratings need to be analyzed week over week.  It is understood that most of the teams play an opponent that is not in Division 1-A.  The result is a lopsided score which will result in lopsided ratings.  What would happen if the best and worst ratings for each team were eliminated?  Could this improve the findings?
3.  Do more work to understand the poor results when picking the home team.  Should the calculation add points to take into account "Home Field Advantage", like the oddsmakers do?  Will this skew the results so that more home teams results are better?
4.  Is there a way to fine tune the ratings to have a better result.  While the ratings up to now have been secretive, there might need to be some work done in R to analyze this.